{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_predict,cross_val_score,train_test_split\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "                             , precision_recall_fscore_support, accuracy_score, roc_auc_score) \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    return csr_matrix(\n",
    "        (loader['data'], loader['indices'], loader['indptr']),\n",
    "        shape=loader['shape']\n",
    "    )\n",
    "\n",
    "def PlotConfusionMatrix(y_test,pred,y_test_dismiss,y_test_click):\n",
    "   \n",
    "    cfn_matrix = confusion_matrix(y_test,pred)\n",
    "    cfn_norm_matrix = np.array([[1.0 / y_test_dismiss,1.0/y_test_dismiss],[1.0/y_test_click,1.0/y_test_click]])\n",
    "    norm_cfn_matrix = cfn_matrix * cfn_norm_matrix\n",
    "\n",
    "    fig = plt.figure(figsize=(9,3))\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    sns.heatmap(cfn_matrix,cmap='coolwarm_r',linewidths=0.5,annot=True,ax=ax)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Real Classes')\n",
    "    plt.xlabel('Predicted Classes')\n",
    "\n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    sns.heatmap(norm_cfn_matrix,cmap='coolwarm_r',linewidths=0.5,annot=True,ax=ax)\n",
    "\n",
    "    plt.title('Normalized Confusion Matrix')\n",
    "    plt.ylabel('Real Classes')\n",
    "    plt.xlabel('Predicted Classes')\n",
    "    plt.show()\n",
    "    \n",
    "    print('---Classification Report---')\n",
    "    print(classification_report(y_test,pred))\n",
    "    \n",
    "def plotCurves(y_test, pred_prob):\n",
    "    fig = plt.figure(figsize=(9,5))\n",
    "    ax1 = fig.add_subplot(1,2,1)\n",
    "    ax1.set_xlim([-0.05,1.05])\n",
    "    ax1.set_ylim([-0.05,1.05])\n",
    "    ax1.set_xlabel('Recall')\n",
    "    ax1.set_ylabel('Precision')\n",
    "    ax1.set_title('PR Curve')\n",
    "\n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    ax2.set_xlim([-0.05,1.05])\n",
    "    ax2.set_ylim([-0.05,1.05])\n",
    "    ax2.set_xlabel('False Positive Rate')\n",
    "    ax2.set_ylabel('True Positive Rate')\n",
    "    ax2.set_title('ROC Curve')\n",
    "\n",
    "    #for w,k in zip([1, 13, 20 ],'bgr'): # 'bgrcmykw'):\n",
    "    p,r,thresholds1 = precision_recall_curve(y_test,pred_prob)\n",
    "    fpr, tpr, thresholds2 = roc_curve(y_test,pred_prob)\n",
    "    ax1.plot(r,p)\n",
    "    ax2.plot(fpr,tpr) \n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def evaluateClassifier(clf, X_train, y_train, X_test, y_test, threshold=None, plotROC=False):     \n",
    "\n",
    "    y_test_dismiss = y_test.value_counts()[0]\n",
    "    y_test_click = y_test.value_counts()[1]\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    pred_proba = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "    if threshold is None:\n",
    "        pred = clf.predict(X_test)\n",
    "    else:\n",
    "        pred_mine = np.where(pred_proba > threshold, 1, 0)\n",
    "        pred = pred_mine\n",
    "        \n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    report = precision_recall_fscore_support(y_test, pred, average=None, labels=[0, 1])\n",
    "    # We should pass the probability estimates of the positive class as the second parameter to roc curve\n",
    "    rocScore = roc_auc_score(y_test, pred_proba)\n",
    "        \n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, pred_proba)\n",
    "    aucScore = auc(recall, precision)\n",
    "\n",
    "    #PlotConfusionMatrix(y_test,pred,y_test_dismiss,y_test_click) \n",
    "    #input()         \n",
    "        \n",
    "    if(plotROC):\n",
    "        plotCurves(y_test, pred_proba)\n",
    "    \n",
    "    accuracy = float(\"{:.2f}\".format(accuracy))\n",
    "    rocScore = float(\"{:.2f}\".format(rocScore))\n",
    "    aucScore = float(\"{:.2f}\".format(aucScore))\n",
    "    precisions = report[0] \n",
    "    recalls = report[1] \n",
    "    fscores = report[2]\n",
    "    supports = report[3]\n",
    "        \n",
    "    return (accuracy, rocScore, aucScore, np.around(precisions, 3), \n",
    "            np.around(recalls, 2), np.around(fscores, 2), np.around(supports, 2))     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def selectImportantApps(appList, df, numMostCommonApps = 30, numAppsToSelect = 6):\n",
    "    from sklearn.feature_selection import SelectKBest, mutual_info_classif, SelectPercentile, f_classif, chi2\n",
    "    \n",
    "    notifApplistMatrix = appList[df['mask'],:numMostCommonApps] \n",
    "    X = pd.DataFrame(df['mask'])\n",
    "    for i in range(notifApplistMatrix.shape[1]):\n",
    "        colName = 'app' + str(i)\n",
    "        appArray = np.squeeze(np.asarray(notifApplistMatrix[:, i].todense()))\n",
    "        X[colName] = appArray\n",
    "    X.drop('mask', axis=1, inplace=True)\n",
    "    y = df['interaction'] \n",
    "    \n",
    "    selector = SelectPercentile(f_classif, percentile=20)\n",
    "    selector.fit(X, y)\n",
    "    scores = selector.scores_\n",
    "    \n",
    "    selectedAppNumbers = scores.argsort()[-numAppsToSelect:][::-1]\n",
    "    return selectedAppNumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addAppsToDF(df, appList, selectedAppNumbers):\n",
    "    notifApplistMatrix = appList[df['mask'], :]\n",
    "    notifApplistMatrix = notifApplistMatrix[:, selectedAppNumbers]\n",
    "    for i in range(len(selectedAppNumbers)):\n",
    "        colName = 'app' + str(selectedAppNumbers[i])\n",
    "        appArray = np.squeeze(np.asarray(notifApplistMatrix[:, i].todense()))\n",
    "        df[colName] = appArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNotifsIdsTrainTestSplit():\n",
    "    FILE = \"notifsIds_split_train_test.npy\"\n",
    "    notifsIds = np.load(FILE)\n",
    "    trainNotifsIds= notifsIds[0]\n",
    "    testNotifsIds= notifsIds[1]\n",
    "    return trainNotifsIds, testNotifsIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#notifId = 1386267\n",
    "df0 = pd.read_csv('./df0.csv')\n",
    "df1= pd.read_csv('./df1.csv')\n",
    "df2= pd.read_csv('./df2.csv')\n",
    "df3= pd.read_csv('./df3.csv')\n",
    "df4= pd.read_csv('./df4.csv')\n",
    "df = pd.concat([df0, df1, df2, df3, df4])\n",
    "#df = df[df['wrapper_id'] == notifId]  \n",
    "df.drop(['Unnamed: 0', 'weekday', 'time', 'mainState', 'phoneModel'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mask', 'wrapper_id', 'interaction', 'numApps'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "appList = load_sparse_csr(\"../data/app_list_csr.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#condition = appList.sum(axis=0) > 400000\n",
    "#condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Few investigation shows that AppList is sorted (decreasing order) based on the number of users.\n",
    "==> So, we just consider first 30 applications __"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#selectedAppNumbers = [11, 18, 16, 20, 6, 3]\n",
    "selectedAppNumbers = selectImportantApps(appList=appList, df = df, numMostCommonApps = 30, numAppsToSelect = 6)\n",
    "addAppsToDF(df=df, appList=appList, selectedAppNumbers=selectedAppNumbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=18, random_state=1)\n",
    "svdColumns = svd.fit_transform(appList)\n",
    "notifSVD = svdColumns[df['mask'], :]\n",
    "for i in range(notifSVD.shape[1]):\n",
    "    colName = 'svd' + str(i)\n",
    "    df[colName] = notifSVD[:, i]\n",
    "    #df[colName].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainNotifsIds, testNotifsIds = getNotifsIdsTrainTestSplit()\n",
    "trainMask = np.in1d(df['wrapper_id'], trainNotifsIds)\n",
    "testMask = np.in1d(df['wrapper_id'], testNotifsIds)\n",
    "X = df.drop('numApps', axis=1)\n",
    "y = df['interaction']\n",
    "X_train, y_train = X[trainMask], y[trainMask]\n",
    "X_test, y_test = X[testMask], y[testMask] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taherian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/taherian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/taherian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/home/taherian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/taherian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/taherian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "mask_numClicks_series = X_train.groupby('mask')['interaction'].sum() \n",
    "mask_numNotifs_series = X_train.groupby('mask')['interaction'].count() \n",
    "mask_clickRatio_series = (1.0 * mask_numClicks_series) / mask_numNotifs_series\n",
    "\n",
    "X_train['clickRatio'] = 0\n",
    "X_train['clickRatio'] = X_train['mask'].apply(lambda mask: mask_clickRatio_series.loc[mask])\n",
    "X_test['clickRatio'] = 0\n",
    "X_test['clickRatio'] = X_test['mask'].apply(lambda mask: mask_clickRatio_series.loc[mask] \n",
    "                                            if mask in mask_clickRatio_series.index else 0)\n",
    "X_train.drop(['mask', 'wrapper_id', 'interaction'], inplace=True, axis=1)\n",
    "X_test.drop(['mask', 'wrapper_id', 'interaction'], inplace=True, axis=1)\n",
    "del df, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build model just by features of appList, without considering clickRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************** weight = 13.000000 ****************\n",
      "(0.57, 0.63, 0.1, array([ 0.956,  0.088]), array([ 0.57,  0.61]))\n",
      "**************** weight = 14.000000 ****************\n",
      "(0.51, 0.63, 0.1, array([ 0.959,  0.084]), array([ 0.5 ,  0.68]))\n",
      "**************** weight = 15.000000 ****************\n",
      "(0.46, 0.63, 0.1, array([ 0.961,  0.081]), array([ 0.45,  0.73]))\n"
     ]
    }
   ],
   "source": [
    "for weight in [13, 14, 15]:\n",
    "    print(\"**************** weight = %f ****************\" %weight)\n",
    "    clf = LogisticRegression(class_weight={0:1, 1:weight}, n_jobs = 4)\n",
    "    result = (accuracy, rocScore, aucScore, precisions, recalls, fscores, supports) = evaluateClassifier(clf, \n",
    "                X_train.drop('clickRatio', axis=1), y_train, X_test.drop('clickRatio', axis=1), y_test) \n",
    "    print(result[:5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build model just by considering clickRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************** weight = 50.000000 ****************\n",
      "(0.64, 0.67, 0.24, array([ 0.96 ,  0.101]), array([ 0.64,  0.6 ]))\n",
      "**************** weight = 60.000000 ****************\n",
      "(0.59, 0.67, 0.24, array([ 0.959,  0.092]), array([ 0.58,  0.63]))\n",
      "**************** weight = 70.000000 ****************\n",
      "(0.56, 0.67, 0.24, array([ 0.958,  0.088]), array([ 0.55,  0.64]))\n",
      "**************** weight = 80.000000 ****************\n",
      "(0.53, 0.67, 0.24, array([ 0.957,  0.084]), array([ 0.52,  0.65]))\n",
      "**************** weight = 90.000000 ****************\n",
      "(0.53, 0.67, 0.24, array([ 0.957,  0.084]), array([ 0.52,  0.65]))\n",
      "**************** weight = 100.000000 ****************\n",
      "(0.53, 0.67, 0.24, array([ 0.957,  0.084]), array([ 0.52,  0.65]))\n"
     ]
    }
   ],
   "source": [
    "for weight in [50, 60, 70, 80, 90, 100]:\n",
    "    print(\"**************** weight = %f ****************\" %weight)\n",
    "    clf = LogisticRegression(class_weight={0:1, 1:weight}, n_jobs = 4)\n",
    "    result = (accuracy, rocScore, aucScore, precisions, recalls, fscores, supports) = evaluateClassifier(clf, \n",
    "                    pd.DataFrame(X_train['clickRatio']), y_train, pd.DataFrame(X_test['clickRatio']), y_test) \n",
    "    print(result[:5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build model by considering both appList features and clickRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************** weight = 50.000000 ****************\n",
      "(0.64, 0.68, 0.22, array([ 0.96 ,  0.102]), array([ 0.64,  0.6 ]))\n",
      "**************** weight = 60.000000 ****************\n",
      "(0.59, 0.68, 0.22, array([ 0.959,  0.093]), array([ 0.59,  0.63]))\n",
      "**************** weight = 70.000000 ****************\n",
      "(0.55, 0.68, 0.22, array([ 0.958,  0.087]), array([ 0.55,  0.64]))\n",
      "**************** weight = 80.000000 ****************\n",
      "(0.53, 0.68, 0.22, array([ 0.957,  0.084]), array([ 0.52,  0.65]))\n",
      "**************** weight = 90.000000 ****************\n",
      "(0.53, 0.68, 0.22, array([ 0.957,  0.084]), array([ 0.52,  0.65]))\n",
      "**************** weight = 100.000000 ****************\n",
      "(0.52, 0.68, 0.22, array([ 0.957,  0.083]), array([ 0.51,  0.65]))\n"
     ]
    }
   ],
   "source": [
    "for weight in [50, 60, 70, 80, 90, 100]:\n",
    "    print(\"**************** weight = %f ****************\" %weight)\n",
    "    clf = LogisticRegression(class_weight={0:1, 1:weight}, n_jobs = 4)\n",
    "    result = (accuracy, rocScore, aucScore, precisions, recalls, fscores, supports) = evaluateClassifier(clf, \n",
    "                X_train, y_train, X_test, y_test) \n",
    "    print(result[:5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************** weight = 120.000000 ****************\n",
      "(0.34, 0.68, 0.22, array([ 0.961,  0.074]), array([ 0.31,  0.81]))\n",
      "**************** weight = 150.000000 ****************\n",
      "(0.08, 0.67, 0.22, array([ 0.98 ,  0.064]), array([ 0.02,  1.  ]))\n"
     ]
    }
   ],
   "source": [
    "for weight in [120, 150]:\n",
    "    print(\"**************** weight = %f ****************\" %weight)\n",
    "    clf = LogisticRegression(class_weight={0:1, 1:weight}, n_jobs = 4)\n",
    "    result = (accuracy, rocScore, aucScore, precisions, recalls, fscores, supports) = evaluateClassifier(clf, \n",
    "                X_train, y_train, X_test, y_test) \n",
    "    print(result[:5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Now we check if the improvement is just because of the clickRatio or the features of the appList are effective, too __"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Here we check the clickRatio of test data to see if the click precision of model is better than this base case (sending notifs to everyone) or not; it is 0.063 __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.063154151693838131"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test == 1).sum() / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for max_depth in [3, 5, 8, 11, 20]:\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "    for max_features in [3, 5, 20, X.shape[1]]:\n",
    "        #print(\"**************** weight = %d ****************\" %weight)\n",
    "        print(\"**************** max_depth = %d, max_features=%s****************\" %(max_depth, str(max_features)))\n",
    "        clf = RandomForestClassifier(class_weight={0:1, 1:7}, n_jobs = 4, n_estimators=80, max_depth=max_depth, max_features=max_features) \n",
    "        result = (accuracy, rocScore, aucScore, precisions, recalls, fscores, supports) = evaluateClassifier(clf, X, y) \n",
    "        print(result[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#X = X.drop('numApps', axis=1)\n",
    "max_depth = 8\n",
    "max_features = 5\n",
    "clf = RandomForestClassifier(class_weight={0:1, 1:7}, n_jobs = 4, n_estimators=100, max_depth=max_depth, max_features=max_features) \n",
    "result = (accuracy, rocScore, aucScore, precisions, recalls, fscores, supports) = evaluateClassifier(clf, X, y) \n",
    "print(result[:5])\n",
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X['numApps'] = df['numApps']\n",
    "max_depth = 8\n",
    "max_features = 5\n",
    "clf = RandomForestClassifier(class_weight={0:1, 1:7.2}, n_jobs = 4, n_estimators=100, max_depth=max_depth, max_features=max_features) \n",
    "result = (accuracy, rocScore, aucScore, precisions, recalls, fscores, supports) = evaluateClassifier(clf, X, y) \n",
    "print(result[:5])\n",
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
